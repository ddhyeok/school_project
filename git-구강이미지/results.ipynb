{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageOps\n",
    "import time\n",
    "\n",
    "from models import CAE_v1 \n",
    "from models import CAE_v2\n",
    "from models import Classifier_v1\n",
    "from models import Classifier_v2\n",
    "import method as MM\n",
    "import Grad_CAM \n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "\n",
    "plt.rc('font', size=12)        \n",
    "plt.rc('axes', labelsize=12)   \n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12) \n",
    "    \n",
    "device = torch.device(\"cuda\")\n",
    "print(torch.cuda.get_device_name(device))\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset,ConcatDataset, DataLoader\n",
    "\n",
    "\n",
    "mean=[0.7101, 0.4827, 0.3970]#val mean\n",
    "std=[0.2351, 0.2195, 0.1862]#val std\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "ag_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),  \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n",
    "    transforms.RandomGrayscale(p=0.75),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "path_train='output_dataset/train'\n",
    "\n",
    "path_val='output_dataset/val'\n",
    "\n",
    "path_test='output_dataset/test'\n",
    "\n",
    "\n",
    "trainset_1 = datasets.ImageFolder(root=path_train, transform=transform)\n",
    "print(trainset_1.class_to_idx)\n",
    "\n",
    "trainset_2 = datasets.ImageFolder(root=path_train, transform=ag_transform)\n",
    "print(trainset_2.class_to_idx)\n",
    "\n",
    "trainset=ConcatDataset([trainset_1,trainset_2])\n",
    "\n",
    "valset = datasets.ImageFolder(root=path_val, transform=transform)\n",
    "print(valset.class_to_idx)\n",
    "testset = datasets.ImageFolder(root=path_test, transform=transform)\n",
    "print(testset.class_to_idx)\n",
    "\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}\n",
    "\n",
    "\n",
    "path='model_save/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='model_save/'\n",
    "\n",
    "densenet = torch.load(path+'densenet.pth')\n",
    "densenet.eval()\n",
    "\n",
    "efficientnet = torch.load(path+'efficientnet.pth')\n",
    "efficientnet.eval()\n",
    "\n",
    "resnet = torch.load(path+'resnet.pth')\n",
    "resnet.eval()\n",
    "\n",
    "vgg = torch.load(path+'vgg.pth')\n",
    "vgg.eval()\n",
    "\n",
    "SWIN_T = torch.load(path+'SWIN_T.pth')\n",
    "SWIN_T.eval()\n",
    "\n",
    "Cnn_based_cae_v1 = torch.load(path+'CNN_based_on_CAE_v1.pth')\n",
    "Cnn_based_cae_v1.eval()\n",
    "\n",
    "Cnn_based_cae_v2 = torch.load(path+'CNN_based_on_CAE_v2.pth')\n",
    "Cnn_based_cae_v2.eval()\n",
    "\n",
    "\n",
    "\n",
    "name_list=[\"CNN_based_on_CAE_v1\",\"CNN_based_on_CAE_v2\",\"densenet\",\"efficientnet\",\"resnet\",\"vgg\",\"SWIN_T\"]\n",
    "total_result=[]\n",
    "model_list=[Cnn_based_cae_v1,Cnn_based_cae_v2,densenet,efficientnet,resnet,vgg,SWIN_T]\n",
    "for i,model in zip(name_list,model_list):\n",
    "    with open(path+i+'.json', 'r') as file:\n",
    "        loaded_data = json.load(file)\n",
    "        \n",
    "    start = time.time()\n",
    "    test_acc,test_pred,test_real = MM.test(model, partition)\n",
    "    end = time.time()\n",
    "    \n",
    "    total_result.append(loaded_data)\n",
    "    if i==\"CNN_based_on_CAE_v1\":\n",
    "        total_result[-1]['model']=\"CNN_based_on_CAE\"\n",
    "    if i==\"CNN_based_on_CAE_v2\":\n",
    "        total_result[-1]['model']=\"Residual_Feature_Classifier\"\n",
    "    \n",
    "    total_result[-1]['test_acc']=test_acc\n",
    "    total_result[-1]['test_pred']=test_pred\n",
    "    total_result[-1]['test_real']=test_real\n",
    "    total_result[-1]['inference_time']=end - start\n",
    "    total_result[-1]['num_parameter']=sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "MM.plot_loss_and_accuracy(total_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "\n",
    "for i in range(len(total_result)):\n",
    "    print(total_result[i]['model']+\": \", round(accuracy_score(torch.cat(total_result[i]['test_real']).cpu().detach(),torch.cat(total_result[i]['test_pred']).cpu().detach()),4))\n",
    "    print(total_result[i]['model']+\": \", round(f1_score(torch.cat(total_result[i]['test_real']).cpu().detach(),torch.cat(total_result[i]['test_pred']).cpu().detach()),4))\n",
    "    print(total_result[i]['model']+\": \", round(precision_score(torch.cat(total_result[i]['test_real']).cpu().detach(),torch.cat(total_result[i]['test_pred']).cpu().detach()),4))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[Cnn_based_cae_v1,Cnn_based_cae_v2,densenet,efficientnet,resnet,vgg,SWIN_T]\n",
    "name_list=[\"CNN_based_on_CAE_v1\",\"CNN_based_on_CAE_v2\",\"densenet\",\"efficientnet\",\"resnet\",\"vgg\",\"SWIN_T\"]\n",
    "\n",
    "inference_time={\n",
    "    \"CNN_based_on_CAE_v1\":[],\n",
    "    \"CNN_based_on_CAE_v2\":[],\n",
    "    \"densenet\":[],\n",
    "    \"efficientnet\":[],\n",
    "    \"resnet\":[],\n",
    "    \"vgg\":[],\n",
    "    \"SWIN_T\":[]\n",
    "}\n",
    "for infer_model,name in zip(model_list,name_list):\n",
    "    for l in range(10):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        \n",
    "        MM.test_for_inference_time(infer_model, partition)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        inference_time[name].append(end-start)\n",
    "    print(inference_time[name])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_info=pd.DataFrame(columns=name_list, index=['mean','std','acc'])\n",
    "\n",
    "for i in range(len(total_result)):\n",
    "    total_info.loc['mean',total_result[i]['model']]=np.mean(inference_time[total_result[i]['model']])\n",
    "    total_info.loc['std',total_result[i]['model']]=np.std(inference_time[total_result[i]['model']])\n",
    "    total_info.loc['acc',total_result[i]['model']]=total_result[i]['test_acc']\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "plt.figure()\n",
    "sns.relplot(data=total_info.transpose().reset_index(drop=False),\n",
    "                x='mean',y='acc',style='index',hue=\"index\",s=300)\n",
    "total_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path+'CAE_v2.json', 'r') as file:\n",
    "        CAE_loss = json.load(file)\n",
    "f=plt.figure(figsize=(10,5))\n",
    "for type,num in zip([CAE_loss['train_losses'],CAE_loss['val_losses']],[1,2]):\n",
    "        ax=f.add_subplot(1,2,num)\n",
    "        ax.plot( type, label=('train_losses' if num==1 else 'val_losses'))\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('mse')\n",
    "        ax.set_title(('train_losses' if num==1 else 'val_losses'))\n",
    "        ax.grid()\n",
    "        ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_nor(image):\n",
    "    mean=torch.tensor([0.7101, 0.4827, 0.3970])#val mean\n",
    "    std=torch.tensor([0.2351, 0.2195, 0.1862])#val std\n",
    "    raw_=(image * std) + mean\n",
    "    return raw_    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "path='model_save/'\n",
    "\n",
    "model = torch.load(path+'CNN_based_on_CAE_v2.pth')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "grad_cam = Grad_CAM.GradCam(model)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(partition['test'],\n",
    "                                        batch_size=1,\n",
    "                                             shuffle=True,num_workers=2)\n",
    "i=0\n",
    "total_cam=[]\n",
    "total_pred=[]\n",
    "total_label=[]\n",
    "total_images=[]\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    if labels==1:\n",
    "    \n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')     \n",
    "        cam, pred = grad_cam(images)\n",
    "    \n",
    "        total_cam.append(cam)\n",
    "        total_label.append(labels.cpu().detach().numpy())\n",
    "        total_pred.append([float(f\"{AA:.4f}\") for AA in pred.cpu().detach().numpy()[0]  ])\n",
    "        total_images.append(images)\n",
    "\n",
    "        i+=1\n",
    "        \n",
    "    if i==20 :\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(20):\n",
    "    f=plt.figure(figsize=(10,5))\n",
    "    plt.axis('off')\n",
    "    cam=np.uint8(255*cv2.resize(total_cam[a].cpu().detach().numpy(),None, fx=32,fy=32, interpolation=cv2.INTER_LINEAR))#cv2.INTER_NEAREST))#cv2.INTER_CUBIC))#cv2.INTER_LANCZOS4))\n",
    "    cam=255-cam\n",
    "    \n",
    "    heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    original=total_images[a][0].transpose(0,2).transpose(0,1).cpu().detach()\n",
    "    raw_image=inverse_nor(original)\n",
    "\n",
    "    plt.title('real:'+str(total_label[a][0])+', pred:'+str(total_pred[a]))\n",
    "    \n",
    "    ax1=f.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(raw_image)\n",
    "    ax1.set_title('input Image')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    #plt.subplot(1, 3, 2)\n",
    "    #plt.imshow(heatmap)\n",
    "    #plt.title('Grad-CAM Heatmap')\n",
    "\n",
    "\n",
    "    ax2=f.add_subplot(1, 2, 2)    \n",
    "    ax2.imshow(raw_image)\n",
    "    cax=ax2.imshow(heatmap, cmap='jet',  alpha=0.4) \n",
    "    ax2.set_title('result Image')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    f.colorbar(plt.cm.ScalarMappable(cmap='jet'), ax=[ax1, ax2],location='bottom',orientation='horizontal')\n",
    "#cbar.set_label(\"COLORMAP_HOT Intensity\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
