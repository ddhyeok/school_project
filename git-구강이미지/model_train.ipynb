{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from models import CAE_v1 \n",
    "from models import CAE_v2\n",
    "from models import Classifier_v1\n",
    "from models import Classifier_v2\n",
    "import method as MM\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "sns.set_theme(style=\"white\", context=\"talk\")\n",
    "\n",
    "plt.rc('font', size=12)        # 기본 폰트 크기\n",
    "plt.rc('axes', labelsize=12)   # x,y축 label 폰트 크기\n",
    "plt.rc('xtick', labelsize=12)  # x축 눈금 폰트 크기 \n",
    "plt.rc('ytick', labelsize=12)  # y축 눈금 폰트 크기\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" )\n",
    "print(torch.cuda.get_device_name(device))\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset,ConcatDataset, DataLoader\n",
    "\n",
    "\n",
    "mean=[0.7101, 0.4827, 0.3970]#val mean\n",
    "std=[0.2351, 0.2195, 0.1862]#val std\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "ag_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 좌우 반전\n",
    "    transforms.RandomVerticalFlip(),  # 상하 반전\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 밝기, 대비, 채도, 색조 \n",
    "    transforms.RandomGrayscale(p=0.75),# 랜덤 그레이 스케일\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "path_train='output_dataset/train'\n",
    "\n",
    "path_val='output_dataset/val'\n",
    "\n",
    "path_test='output_dataset/test'\n",
    "\n",
    "\n",
    "trainset_1 = datasets.ImageFolder(root=path_train, transform=transform)\n",
    "print(trainset_1.class_to_idx)\n",
    "\n",
    "trainset_2 = datasets.ImageFolder(root=path_train, transform=ag_transform)\n",
    "print(trainset_2.class_to_idx)\n",
    "\n",
    "trainset=ConcatDataset([trainset_1,trainset_2])\n",
    "\n",
    "valset = datasets.ImageFolder(root=path_val, transform=transform)\n",
    "print(valset.class_to_idx)\n",
    "testset = datasets.ImageFolder(root=path_test, transform=transform)\n",
    "print(testset.class_to_idx)\n",
    "\n",
    "partition = {'train': trainset, 'val':valset, 'test':testset}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import swin_t\n",
    "\n",
    "SWIN_T = swin_t(\n",
    "    pretrained=False,   \n",
    "    num_classes=2      \n",
    ")\n",
    "SWIN_T=SWIN_T.to(\"cuda\")\n",
    "\n",
    "MM.model_train_eval(SWIN_T,'SWIN_T',50,partition,results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "torch.cuda.empty_cache()\n",
    "efficientnet = models.efficientnet_b0()\n",
    "efficientnet.classifier[1] = nn.Linear(efficientnet.classifier[1].in_features, 2)\n",
    "efficientnet=efficientnet.to('cuda')\n",
    "\n",
    "MM.model_train_eval(efficientnet,'efficientnet',50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "densenet = models.densenet121()\n",
    "densenet.classifier = nn.Linear(densenet.classifier.in_features, 2)\n",
    "densenet=densenet.to('cuda')\n",
    "\n",
    "MM.model_train_eval(densenet,'densenet',50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "vgg = models.vgg16()\n",
    "vgg.classifier[6] = torch.nn.Linear(vgg.classifier[6].in_features, 2)\n",
    "vgg=vgg.to('cuda')\n",
    "\n",
    "MM.model_train_eval(vgg,'vgg',50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "resnet = models.resnet18()\n",
    "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 2)\n",
    "resnet=resnet.to('cuda')\n",
    "\n",
    "MM.model_train_eval(resnet,'resnet',50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "CAE_v1_model =CAE_v1.CAE(img_size=[192, 384],filter=32)\n",
    "CAE_v1_train_losses,CAE_v1_val_losses=MM.CAE_train_eval(CAE_v1_model,50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(10,5))\n",
    "for type,num in zip([CAE_v1_train_losses,CAE_v1_val_losses],[1,2]):\n",
    "        ax=f.add_subplot(1,2,num)\n",
    "        ax.plot( type, label=('train_losses' if num==1 else 'val_losses'))\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('mse')\n",
    "        ax.set_title(('train_losses' if num==1 else 'val_losses'))\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "cae_results=[]\n",
    "cae_results.append({\n",
    "        'model': 'CAE_v1',\n",
    "        'train_losses':CAE_v1_train_losses,\n",
    "        'val_losses': CAE_v1_val_losses,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='model_save/'\n",
    "\n",
    "#with open(path+cae_results[0]['model']+'.json', 'w') as file:\n",
    "#        json.dump(cae_results[0], file)\n",
    "        \n",
    "#torch.save(CAE_v1_model, 'model_save/cae_v1.pth')\n",
    "CAE_v1_model = torch.load('model_save/cae_v1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "CNN_based_on_CAE_v1=Classifier_v1.CAEClassifier(CAE_v1_model)\n",
    "CNN_based_on_CAE_v1=CNN_based_on_CAE_v1.to(\"cuda\")\n",
    "MM.model_train_eval(CNN_based_on_CAE_v1,'CNN_based_on_CAE_v1',50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "CAE_v2_model =CAE_v2.CAE()\n",
    "CAE_v2_train_losses,CAE_v2_val_losses=MM.CAE_train_eval(CAE_v2_model,50,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(10,5))\n",
    "for type,num in zip([CAE_v2_train_losses,CAE_v2_val_losses],[1,2]):\n",
    "        ax=f.add_subplot(1,2,num)\n",
    "        ax.plot( type, label=('train_losses' if num==1 else 'val_losses'))\n",
    "        \n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('mse')\n",
    "        ax.set_title(('train_losses' if num==1 else 'val_losses'))\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "cae_results=[]\n",
    "cae_results.append({\n",
    "        'model': 'CAE_v2',\n",
    "        'train_losses':CAE_v2_train_losses,\n",
    "        'val_losses': CAE_v2_val_losses,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='model_save/'\n",
    "\n",
    "#with open(path+cae_results[0]['model']+'.json', 'w') as file:\n",
    "#        json.dump(cae_results[0], file)\n",
    "        \n",
    "#torch.save(CAE_v2_model, 'model_save/cae_v2.pth')\n",
    "CAE_v2_model = torch.load('model_save/cae_v2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_based_on_CAE_v2=Classifier_v2.CAEClassifier(CAE_v2_model)\n",
    "CNN_based_on_CAE_v2=CNN_based_on_CAE_v2.to(\"cuda\")\n",
    "MM.model_train_eval(CNN_based_on_CAE_v2,'CNN_based_on_CAE_v2',1,partition,results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM.plot_loss_and_accuracy(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='model_save/'\n",
    "\n",
    "\n",
    "torch.save(SWIN_T, path+'SWIN_T.pth')\n",
    "SWIN_T = torch.load(path+'SWIN_T.pth')\n",
    "SWIN_T.eval()\n",
    "test_acc,test_pred,test_real = MM.test(SWIN_T, partition)\n",
    "print(test_acc)\n",
    "\n",
    "torch.save(efficientnet, path+'efficientnet.pth')\n",
    "efficientnet = torch.load(path+'efficientnet.pth')\n",
    "efficientnet.eval()\n",
    "test_acc,test_pred,test_real = MM.test(efficientnet, partition)\n",
    "print(test_acc)\n",
    "\n",
    "torch.save(densenet, path+'densenet.pth')\n",
    "densenet = torch.load(path+'densenet.pth')\n",
    "densenet.eval()\n",
    "test_acc,test_pred,test_real = MM.test(densenet, partition)\n",
    "print(test_acc)\n",
    "\n",
    "\n",
    "torch.save(vgg, path+'vgg.pth')\n",
    "vgg = torch.load(path+'vgg.pth')\n",
    "vgg.eval()\n",
    "test_acc,test_pred,test_real = MM.test(vgg, partition)\n",
    "print(test_acc)\n",
    "\n",
    "\n",
    "\n",
    "torch.save(resnet, path+'resnet.pth')\n",
    "resnet = torch.load(path+'resnet.pth')\n",
    "resnet.eval()\n",
    "test_acc,test_pred,test_real = MM.test(resnet, partition)\n",
    "print(test_acc)\n",
    "\n",
    "\n",
    "torch.save(vgg, path+'vgg.pth')\n",
    "vgg = torch.load(path+'vgg.pth')\n",
    "vgg.eval()\n",
    "test_acc,test_pred,test_real = MM.test(vgg, partition)\n",
    "print(test_acc)\n",
    "\n",
    "\n",
    "torch.save(CNN_based_on_CAE_v1, path+'CNN_based_on_CAE_v1.pth')\n",
    "CNN_based_CAE_on_v1 = torch.load(path+'CNN_based_on_CAE_v1.pth')\n",
    "CNN_based_CAE_on_v1.eval()\n",
    "test_acc,test_pred,test_real = MM.test(CNN_based_on_CAE_v1, partition)\n",
    "print(test_acc)\n",
    "\n",
    "torch.save(CNN_based_on_CAE_v2, path+'CNN_based_on_CAE_v2.pth')\n",
    "CNN_based_on_CAE_v2 = torch.load(path+'CNN_based_on_CAE_v2.pth')\n",
    "CNN_based_on_CAE_v2.eval()\n",
    "test_acc,test_pred,test_real = MM.test(CNN_based_on_CAE_v2, partition)\n",
    "print(test_acc)\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "for i in range(len(results)):\n",
    "    results[i]['test_pred']=torch.cat(results[i]['test_pred']).cpu().reshape(-1).tolist()\n",
    "    results[i]['test_real']=torch.cat(results[i]['test_real']).cpu().reshape(-1).tolist()\n",
    "    \n",
    "    with open(path+results[i]['model']+'.json', 'w') as file:\n",
    "        json.dump(results[i], file)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
